{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f77be0c-595f-412c-a3ee-90b71eb2c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "os.environ['http_proxy']=\"http://proxy-igk.intel.com:911\"\n",
    "os.environ['https_proxy']=\"http://proxy-igk.intel.com:911\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a498b22-fb7f-4fa1-a4d8-a0d983eb4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5158e553-3355-46af-879b-e7ef09058aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Document Splitter\n",
    "from typing import List\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
    "from langchain_community.document_loaders import (\n",
    "    CSVLoader,\n",
    "    EverNoteLoader,\n",
    "    PDFMinerLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredEPubLoader,\n",
    "    UnstructuredHTMLLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    UnstructuredODTLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    UnstructuredWordDocumentLoader, )\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25410751-e4a5-4348-8376-938dc4ffd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FOLDER = \"./ovms/html_files/\"\n",
    "\n",
    "TEXT_SPLITERS = {\n",
    "    \"Character\": CharacterTextSplitter,\n",
    "    \"RecursiveCharacter\": RecursiveCharacterTextSplitter,\n",
    "    \"Markdown\": MarkdownTextSplitter,\n",
    "}\n",
    "\n",
    "LOADERS = {\n",
    "    \".csv\": (CSVLoader, {}),\n",
    "    \".doc\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".enex\": (EverNoteLoader, {}),\n",
    "    \".epub\": (UnstructuredEPubLoader, {}),\n",
    "    \".html\": (UnstructuredHTMLLoader, {}),\n",
    "    \".md\": (UnstructuredMarkdownLoader, {}),\n",
    "    \".odt\": (UnstructuredODTLoader, {}),\n",
    "    \".pdf\": (PDFMinerLoader, {}),\n",
    "    \".ppt\": (UnstructuredPowerPointLoader, {}),\n",
    "    \".pptx\": (UnstructuredPowerPointLoader, {}),\n",
    "    \".txt\": (TextLoader, {\"encoding\": \"utf8\"}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed9afff-df0f-42f2-8aa7-6b5fff9f794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    helper for loading a single document\n",
    "\n",
    "    Params:\n",
    "      file_path: document path\n",
    "    Returns:\n",
    "      documents loaded\n",
    "\n",
    "    \"\"\"\n",
    "    ext = \".\" + file_path.rsplit(\".\", 1)[-1]\n",
    "    if ext in LOADERS:\n",
    "        loader_class, loader_args = LOADERS[ext]\n",
    "        loader = loader_class(file_path, **loader_args)\n",
    "        return loader.load()\n",
    "\n",
    "    raise ValueError(f\"File does not exist '{ext}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75374e4c-3af8-44fa-ad8d-f905766cc407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtrawins/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "            model_kwargs={\"device\":\"cpu\"},\n",
    "            show_progress=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12abca7-3074-4c87-8ba1-eb27e4332860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document ./ovms/html_files/ovms_docs_quick_start_guide.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_parameters.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_mediapipe_holistic.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_serving_model.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_mediapipe_conversion.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_troubleshooting.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_shape_custom_node.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demos.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_shape_auto_reload.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_shape_binary_inputs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_clients_kfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_c_api.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_shape_batch_layout.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_mediapipe_object_detection.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_python_support_reference.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_binary_input_tfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_tensorflow_conversion.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_image_classification.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dag.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_deploying_server.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_advanced.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_model_cache.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_bs_auto_reload.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_model_version_policy.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_performance_tuning.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_mediapipe.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_streaming_endpoints.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_binary_input_kfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_mediapipe_multi_model.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_mediapipe_iris.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_shape_dynamic_model.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_models_repository.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_security.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_ensemble.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_custom_loader.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_bs_demultiplexer.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_grpc_api_kfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_rest_api_tfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_clients_tfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_online_config_changes.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_dynamic_input.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_stateful_models.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_metrics.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_cloud_storage.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_features.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_target_devices.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_grpc_api_tfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_binary_input.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_custom_node_development.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demultiplexing.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_text.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_rest_api_kfs.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_binary_input_layout_and_shape.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_server_app.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_demo_mediapipe_image_classification.html...\n",
      "Reading document ./ovms/html_files/ovms_docs_python_support_quickstart.html...\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for file_path in os.listdir(TARGET_FOLDER):\n",
    "    if not file_path.endswith('.html'):\n",
    "        continue\n",
    "    abs_path = os.path.join(TARGET_FOLDER, file_path)\n",
    "    print(f\"Reading document {abs_path}...\", flush=True)\n",
    "    documents.extend(load_single_document(abs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173aee0c-9cfc-4ad6-bdb5-68df52b797f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter_name = \"RecursiveCharacter\"  # PARAM\n",
    "chunk_size=1000  # PARAM\n",
    "chunk_overlap=200  # PARAM\n",
    "text_splitter = TEXT_SPLITERS[spliter_name](chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281c64d8-e188-4712-8aaa-c2d2eb61c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 15/15 [00:45<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db.delete_collection()\n",
    "except:\n",
    "    pass\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc958cd3-72e6-4311-a77f-44eaa147b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='sudo\\n\\ndnf\\n\\ninstall\\n\\ny\\n\\npkg-config\\n\\n&&\\n\\nsudo\\n\\nrpm\\n\\nivh\\n\\nhttps://vault.centos.org/centos/8/AppStream/x86_64/os/Packages/tbb-2018.2-9.el8.x86_64.rpm\\n\\nStart the server:\\n\\nwget\\n\\nhttps://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/2/resnet50-binary-0001/FP32-INT1/resnet50-binary-0001.\\n\\n{xml,bin\\n\\nP\\n\\nmodels/resnet50/1\\n\\n./ovms/bin/ovms\\n\\n--model_name\\n\\nresnet\\n\\n--model_path\\n\\nmodels/resnet50\\n\\nor start as a background process or a daemon initiated by systemctl/initd depending on the Linux distribution and specific hosting requirements.\\n\\nMost of the Model Server documentation demonstrate containers usage, but the same can be achieved with just the binary package.\\n\\nLearn more about model server\\n\\nstarting parameters.\\n\\nNOTE:\\nWhen serving models on AI accelerators, some additional steps may be required to install device drivers and dependencies.\\nLearn more in the Additional Configurations for Hardware documentation.\\n\\nDeploying Model Server in Kubernetes¶' metadata={'source': './ovms/html_files/ovms_docs_deploying_server.html'}\n",
      "page_content='resnet\\n\\n--port\\n\\n9000\\n\\n--rest_port\\n\\n8000\\n\\n--log_level\\n\\nDEBUG\\n\\nThe required Model Server parameters are listed below. For additional configuration options, see the Model Server Parameters section.\\n\\noption description --rm remove the container when exiting the Docker container -d runs the container in the background -v defines how to mount the model folder in the Docker container -p exposes the model serving port outside the Docker container openvino/model_server:latest represents the image name; the ovms binary is the Docker entry point --model_path model location --model_name the name of the model in the model_path --port the gRPC server port --rest_port the REST server port\\n\\nPossible model locations (--model_path):\\n\\nDocker container path that is mounted during start-up\\n\\nGoogle Cloud Storage path gs://<bucket>/<model_path>\\n\\nAWS S3 path s3://<bucket>/<model_path>\\n\\nAzure blob path az://<container>/<model_path>' metadata={'source': './ovms/html_files/ovms_docs_serving_model.html'}\n",
      "page_content='Setup Model Server¶\\n\\nServing a single model is the simplest way to deploy OpenVINO™ Model Server. Only one model is served and the whole configuration is passed via CLI parameters.\\nNote that changing configuration in runtime while serving a single model is not possible. Serving multiple models requires a configuration file that stores settings for all served models.\\nWhen deploying model(s) with a configuration file, you can add or delete models, as well as update their configurations in runtime, without needing to restart the server.\\n\\nServing a Single Model¶\\n\\nBefore starting the container, make sure you have prepared the model for serving.\\n\\nStart the model server by running the following command with your parameters:\\n\\ndocker\\n\\nrun\\n\\n--\\n\\nrm\\n\\nmodels_repository\\n\\nmodels\\n\\n9000\\n\\n9000\\n\\n8000\\n\\n8000\\n\\nopenvino\\n\\nmodel_server\\n\\nlatest \\\\\\n\\n--\\n\\nmodel_path\\n\\npath_to_model\\n\\n--\\n\\nmodel_name\\n\\nmodel_name\\n\\n--\\n\\nport\\n\\n9000\\n\\n--\\n\\nrest_port\\n\\n8000\\n\\n--\\n\\nlog_level\\n\\nDEBUG\\n\\nExample using a ResNet model:\\n\\nmkdir\\n\\np' metadata={'source': './ovms/html_files/ovms_docs_serving_model.html'}\n",
      "page_content='Run command to start the Model Server\\n\\ndocker\\n\\nrun\\n\\n--rm\\n\\nv\\n\\n$(\\n\\npwd\\n\\n)/models/:/models:ro\\n\\np\\n\\n9100:9100\\n\\np\\n\\n8100:8100\\n\\nopenvino/model_server:latest\\n\\n--config_path\\n\\n/models/config.json\\n\\n--port\\n\\n9100\\n\\n--rest_port\\n\\n8100\\n\\n--log_level\\n\\nDEBUG\\n\\nStep 4: Requesting the service¶\\n\\nInput images can be sent to the service requesting resource name image_classification_pipeline. There is an example client doing that:\\n\\nCheck accuracy of the pipeline by running the client in another terminal:\\n\\ncd\\n\\n../../../client/python/tensorflow-serving-api/samples\\nvirtualenv\\n\\n.venv\\n.\\n\\n.venv/bin/activate\\n\\n&&\\n\\npip3\\n\\ninstall\\n\\nr\\n\\nrequirements.txt\\npython3\\n\\ngrpc_predict_resnet.py\\n\\n--pipeline_name\\n\\nimage_classification_pipeline\\n\\n--images_numpy_path\\n\\n../../imgs.npy\\n\\n--labels_numpy_path\\n\\n../../lbs.npy\\n\\n--grpc_port\\n\\n9100\\n\\n--input_name\\n\\nimage\\n\\n--output_name\\n\\nlabel\\n\\n--transpose_input\\n\\nTrue\\n\\n--transpose_method\\n\\nnchw2nhwc\\n\\n--iterations\\n\\n10\\nImage\\n\\ndata\\n\\nrange:\\n\\n0.0\\n\\n255.0\\nStart\\n\\nprocessing:\\n\\nModel\\n\\nname:' metadata={'source': './ovms/html_files/ovms_docs_demo_ensemble.html'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vector_search_top_k = 4\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": vector_search_top_k})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"How to start model server container?\")\n",
    "print(retrieved_docs[0])\n",
    "print(retrieved_docs[1])\n",
    "print(retrieved_docs[2])\n",
    "print(retrieved_docs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d6a7cc-de79-4255-81b3-80ed44f2ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtrawins/.local/lib/python3.10/site-packages/langchain_core/utils/utils.py:161: UserWarning: WARNING! seed is not default parameter.\n",
      "                seed was transferred to model_kwargs.\n",
      "                Please confirm that seed is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base=\"http://ov-spr-19.sclab.intel.com:8002/v1\",\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    temperature=0.1,\n",
    "    seed=5,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba4bc8d-abab-4374-9776-2f531ba62f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt input_variables=['context', 'question'] template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt=PromptTemplate(input_variables=['context', 'question'], \n",
    "                      template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "\n",
    "print(\"prompt\", prompt)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfb2833-a753-4663-abcf-76041cdb8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To start the model server container, you can use the following command:\n",
      "```\n",
      "docker run --rm -v $(pwd)/models:/models:ro -p 9100:9100 -p 8100:8100 openvino/model_server:latest --config_path /models/config.json --port 9100 --rest_port 8100 --log_level DEBUG\n",
      "```\n",
      "This command assumes that you have a configuration file named `config.json` in the `models` directory. You can modify the parameters as needed for your specific use case.\n",
      "\n",
      "If you don't have a configuration file, you can still start the model server by specifying the model path and name as command-line arguments. For example:\n",
      "```\n",
      "docker run --rm -v $(pwd)/models:/models:ro -p 9100:9100 -p 8100:8100 openvino/model_server:latest --model_path /models/resnet50 --model_name resnet --port 9100 --rest_port 8100 --log_level DEBUG\n",
      "```\n",
      "This command assumes that you have a model named `resnet50` in the `models` directory. You can replace `resnet50` with the name of your own model.\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"How to start model server container?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5b1d12-0b36-4818-a6e5-d94868c8c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The OpenVINO Model Server supports various metrics for monitoring and benchmarking purposes, auto scaling of model server instances, and tracking performance without any extra logic on the client side or using network traffic monitoring tools. Some examples of metrics include inference execution queue statistics, model runtime parameters, and usage based on model version, API type, or requested endpoint methods. These metrics are exposed on the /metrics endpoint and are compatible with the Prometheus standard. You can enable additional metrics by listing them in the metric_list flag or json configuration."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Which metrics are supported in the model server? Give examples.\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58217565-fc81-454c-87c7-9590de2c4fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
